{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crypto System v1 - Colab Training\n",
    "\n",
    "Run cells in order (top to bottom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install packages\n",
    "!pip install -q pandas numpy tensorflow scikit-learn ccxt pyarrow pandas-ta matplotlib\n",
    "print(\"✓ Packages installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and setup\n",
    "import os, time\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate, Conv1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "print(\"✓ All imports successful\")\n",
    "\n",
    "# Setup\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CRYPTO SYSTEM v1 - TRAINING\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"✓ GPU: {len(gpus)} device(s)\")\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "else:\n",
    "    print(\"⚠ No GPU detected\")\n",
    "\n",
    "CACHE_DIR = Path(\"/content/all_models/v1\")\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"✓ Cache: {CACHE_DIR}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Generate synthetic data\n",
    "print(\"Generating synthetic data...\")\n",
    "\n",
    "np.random.seed(42)\n",
    "symbols = ['BTC/USDT', 'ETH/USDT', 'SOL/USDT']\n",
    "all_data = {}\n",
    "\n",
    "for symbol in symbols:\n",
    "    n = 2000\n",
    "    timestamps = [datetime.now() - timedelta(hours=i) for i in range(n)][::-1]\n",
    "    returns = np.random.normal(0.0005, 0.015, n)\n",
    "    prices = 90000 * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    all_data[symbol] = pd.DataFrame({\n",
    "        'timestamp': timestamps,\n",
    "        'open': prices.copy(),\n",
    "        'high': prices * (1 + np.abs(np.random.normal(0, 0.003, n))),\n",
    "        'low': prices * (1 - np.abs(np.random.normal(0, 0.003, n))),\n",
    "        'close': prices * (1 + np.random.normal(0, 0.005, n)),\n",
    "        'volume': np.random.uniform(100000, 500000, n)\n",
    "    })\n",
    "    print(f\"  ✓ {symbol}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Feature engineering\n",
    "print(\"Computing features...\")\n",
    "\n",
    "for symbol in symbols:\n",
    "    df = all_data[symbol]\n",
    "    \n",
    "    # Basic features\n",
    "    df['log_return'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    df['volatility'] = df['log_return'].rolling(14).std()\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['close'].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
    "    rs = gain / (loss + 1e-8)\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD\n",
    "    ema_12 = df['close'].ewm(span=12).mean()\n",
    "    ema_26 = df['close'].ewm(span=26).mean()\n",
    "    df['macd'] = ema_12 - ema_26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "    \n",
    "    # Volume features\n",
    "    df['volume_ma'] = df['volume'].rolling(20).mean()\n",
    "    df['volume_ratio'] = df['volume'] / (df['volume_ma'] + 1e-8)\n",
    "    \n",
    "    # ATR\n",
    "    df['high_low'] = df['high'] - df['low']\n",
    "    df['high_close'] = abs(df['high'] - df['close'].shift(1))\n",
    "    df['low_close'] = abs(df['low'] - df['close'].shift(1))\n",
    "    df['true_range'] = df[['high_low', 'high_close', 'low_close']].max(axis=1)\n",
    "    df['atr'] = df['true_range'].rolling(14).mean()\n",
    "    \n",
    "    all_data[symbol] = df.fillna(method='ffill').fillna(method='bfill')\n",
    "    print(f\"  ✓ {symbol}\")\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Create sequences\n",
    "print(\"Creating sequences...\")\n",
    "\n",
    "feature_cols = ['open', 'high', 'low', 'close', 'volume', 'log_return', 'volatility', 'rsi', 'macd', 'volume_ratio', 'atr']\n",
    "all_X, all_y = [], []\n",
    "\n",
    "for symbol in symbols:\n",
    "    df = all_data[symbol]\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(df) - 60 - 1):\n",
    "        X.append(df[feature_cols].iloc[i:i+60].values)\n",
    "        y.append(df['close'].iloc[i+60])\n",
    "    \n",
    "    all_X.append(np.array(X))\n",
    "    all_y.append(np.array(y))\n",
    "    print(f\"  ✓ {symbol}: {np.array(X).shape}\")\n",
    "\n",
    "X_combined = np.concatenate(all_X, axis=0)\n",
    "y_combined = np.concatenate(all_y, axis=0)\n",
    "\n",
    "n_train = int(len(X_combined) * 0.7)\n",
    "n_val = int(len(X_combined) * 0.15)\n",
    "\n",
    "X_train = X_combined[:n_train]\n",
    "X_val = X_combined[n_train:n_train+n_val]\n",
    "X_test = X_combined[n_train+n_val:]\n",
    "\n",
    "y_train = y_combined[:n_train]\n",
    "y_val = y_combined[n_train:n_train+n_val]\n",
    "y_test = y_combined[n_train+n_val:]\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]} | Val: {X_val.shape[0]} | Test: {X_test.shape[0]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Build model\n",
    "print(\"Building model...\")\n",
    "\n",
    "n_features = X_train.shape[2]\n",
    "input_1h = Input(shape=(60, n_features), name='input_1h')\n",
    "input_15m = Input(shape=(60, n_features), name='input_15m')\n",
    "\n",
    "# Stream 1: LSTM\n",
    "x1 = LSTM(64, activation='relu', return_sequences=True)(input_1h)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "x1 = LSTM(32, activation='relu', return_sequences=False)(x1)\n",
    "x1 = Dropout(0.2)(x1)\n",
    "\n",
    "# Stream 2: Conv1D + LSTM\n",
    "x2 = Conv1D(filters=32, kernel_size=3, activation='relu')(input_15m)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "x2 = LSTM(32, activation='relu', return_sequences=False)(x2)\n",
    "x2 = Dropout(0.2)(x2)\n",
    "\n",
    "# Merge\n",
    "combined = Concatenate()([x1, x2])\n",
    "z = Dense(32, activation='relu')(combined)\n",
    "z = Dropout(0.2)(z)\n",
    "z = Dense(16, activation='relu')(z)\n",
    "output = Dense(1, name='price')(z)\n",
    "\n",
    "model = Model(inputs=[input_1h, input_15m], outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "print(f\"✓ Model: {model.count_params():,} params\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Train model\n",
    "print(\"Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "history = model.fit(\n",
    "    [X_train, X_train], y_train,\n",
    "    validation_data=([X_val, X_val], y_val),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    callbacks=[\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "    ],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(f\"\\n✓ Training completed in {training_time:.0f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Evaluate and save\n",
    "print(\"Evaluating...\")\n",
    "y_pred = model.predict([X_test, X_test], verbose=0)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mape = np.mean(np.abs((y_test - y_pred.flatten()) / y_test)) * 100\n",
    "\n",
    "print(f\"  MAE:  ${mae:.2f}\")\n",
    "print(f\"  RMSE: ${rmse:.2f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\\n\")\n",
    "\n",
    "# Save model\n",
    "model_path = CACHE_DIR / \"crypto_v1_model.h5\"\n",
    "model.save(str(model_path))\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"✓ SUCCESS!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Model saved: {model_path}\")\n",
    "print(f\"Size: {model_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "print()\n",
    "print(\"Next: Train with real Binance data (45-60 min)\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
